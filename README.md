# ğŸ›ï¸ Retail Demand Forecasting using Spark + Streamlit

This project builds a scalable pipeline for **product-level demand forecasting** and **inventory recommendation** using PySpark, MLlib, and Streamlit. It processes over 1M transactions and reveals sales patterns around holidays, seasons, and product trends.

---

## ğŸ§­ Project Narrative

> How can a retailer avoid stockouts and overstock â€” especially during seasonal spikes?

We explored 1M+ UK retail transactions across 2 years and built:

* ğŸ“ˆ A product-month demand forecasting model (Random Forest, RMSE \~\$421)
* ğŸ“¦ A classifier that predicts whether to **Increase**, **Maintain**, or **Reduce** stock (92% accuracy)
* ğŸ¯ Insights about **holiday impact** and **seasonal trends**

---

## ğŸ’¡ Problem Statement

> Predict monthly sales and recommend inventory actions per product by learning from past sales, seasonality, and public holiday effects.

---

## ğŸ”§ Tech Stack

* `PySpark` â€“ Big data processing + MLlib modeling
* `Pandas` â€“ Local EDA + metric summaries
* `Streamlit` â€“ Dashboard UI for business users
* `Docker + Taskfile` â€“ Reproducible build + run steps

---

## ğŸ“ Folder Layout

```
data/                          â†’ raw retail & holiday data  
scripts/                       â†’ Spark jobs & analysis scripts  
output/                        â†’ Model inputs, predictions, metrics  
streamlit_app.py               â†’ Interactive forecast dashboard  
Taskfile.yml                   â†’ Run pipeline with `task all:train`  
```

---

## ğŸ“ˆ Dashboard Sections (Narrative-Driven)

| Section                      | What It Answers                          |
| ---------------------------- | ---------------------------------------- |
| ğŸ§­ Intro                     | Why forecasting matters                  |
| ğŸ”® Product Forecast Explorer | What future sales look like              |
| ğŸ Holiday Products          | What sells best during holidays          |
| ğŸ“† Quarterly Trends          | When each product peaks                  |
| ğŸ„ Holiday Comparison        | Is New Year beating Christmas?           |
| ğŸ† Holiday Impact            | Which holidays actually move revenue?    |
| ğŸ“¦ Inventory Classifier      | What stock action to take (92% accuracy) |

---

## ğŸ§ª Modeling Pipeline

1. **`spark_eda.py`** â€“ Cleans raw transactions and monthly aggregates
2. **`spark_features.py`** â€“ Adds lag, rolling avg, sales\_delta, holiday flags
3. **`train_model.py`** â€“ Trains RandomForestRegressor (uses `TrainValidationSplit`)
4. **`train_inventory_model.py`** â€“ Trains classifier on stock\_decision (accuracy \~92%)
5. **`analyze_*.py` scripts** â€“ Seasonal + holiday trends

---

## ğŸ“Š Key Results

* ğŸ” Regression RMSE: **\$421.12**, MAE: **\$174.21**
* ğŸ“¦ Classifier Accuracy: **91.89%**
* ğŸ† Spring Bank Holiday outperformed Christmas in revenue
* ğŸ„ January sales exceeded December in some years

---

## ğŸš€ Run the Full Pipeline

```bash
docker-compose build

# Feature generation & modeling
task spark:eda
task spark:features
task train:regression
task train:inventory

# Exploratory analysis
task analyze:holidays
task analyze:products
task analyze:seasonality

# Streamlit dashboard
task serve
```

---

## ğŸ“ Sample Output

`model_metrics.json`:

```json
{
  "RMSE": 421.12,
  "MAE": 174.21,
  "Best Hyperparameters": {
    "numTrees": 10,
    "maxDepth": 10
  }
}
```

`model_metrics_inventory.json`:

```json
{
  "accuracy": 0.9189,
  "f1": 0.9176,
  "weightedPrecision": 0.9200,
  "weightedRecall": 0.9189
}
```

---

## ğŸ§  Lessons Learned

* Demand varies significantly by product and season â€” models need **context-aware features**
* Holidays like **Substitute Boxing Day** and **Spring Bank** matter more than expected
* Class imbalance and label encoding can silently impact classifiers â€” verify them visually
* Small MAE at the global level can hide **high variance at product level** â†’ use product-specific MAE

---

## ğŸ“¦ Future Enhancements

* Use **Word2Vec / BERT** embeddings for product names
* Extend pipeline for **weekly forecasts** or **real-time Kafka integration**
* Add **profit-aware recommendations** (margin Ã— demand Ã— inventory)